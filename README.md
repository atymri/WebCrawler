# WebCrawler

A simple C# console application that crawls a website starting from a URL, collects all links, and saves them to a file.

## Features

- Recursively visits links on a website
- Saves all discovered links to a text file

## Usage

1. Run the program.
2. Enter the starting URL.
3. The program will crawl and save links to `crawled_links.txt`.

## Requirements

- .NET 6 or newer
- Internet connection

## License

MIT License
